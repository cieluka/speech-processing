{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOry8hMWyP6szy5PFBU8vkA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "print(torch.__version__)\n",
        "print(torchaudio.__version__)\n",
        "\n",
        "torch.random.manual_seed(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available()else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "ij3twAIdGyaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "from torchaudio.utils import download_asset\n",
        "\n",
        "speech_file = download_asset(\"/content/0017_001731.wav\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NDasI5hzHhgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "print(\"sample rate:\",bundle.sample_rate)\n",
        "print(\"labels:\",bundle.get_labels())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KAQJoRAbH8Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = bundle.get_model().to(device)\n",
        "print(model.__class__)"
      ],
      "metadata": {
        "id": "HyUQpiWqIfrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Audio(speech_file)"
      ],
      "metadata": {
        "id": "fuHluYhbIsBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waveform,sample_rate = torchaudio.load(speech_file)\n",
        "waveform = waveform.to(device)\n",
        "\n",
        "if sample_rate != bundle.sample_rate:\n",
        "    waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)"
      ],
      "metadata": {
        "id": "3yObhZZMI2eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  features,_ = model.extract_features(waveform)"
      ],
      "metadata": {
        "id": "ADJ4eypAJQtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(len(features), 1, figsize=(16, 4.3 * len(features)))\n",
        "for i, feats in enumerate(features):\n",
        "    ax[i].imshow(feats[0].cpu(), interpolation=\"nearest\")\n",
        "    ax[i].set_title(f\"Feature from transformer layer {i+1}\")\n",
        "    ax[i].set_xlabel(\"Feature dimension\")\n",
        "    ax[i].set_ylabel(\"Frame (time-axis)\")\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "2mQhdsLrJkv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "    emission, _ = model(waveform)"
      ],
      "metadata": {
        "id": "bIeKosHbJrzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(emission[0].cpu().T, interpolation=\"nearest\")\n",
        "plt.title(\"Classification result\")\n",
        "plt.xlabel(\"Frame (time-axis)\")\n",
        "plt.ylabel(\"Class\")\n",
        "plt.tight_layout()\n",
        "print(\"Class labels:\", bundle.get_labels())"
      ],
      "metadata": {
        "id": "heWvL1uNJub_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GreedyCTCDecoder(torch.nn.Module):\n",
        "  def __init__(self, labels, blank=0):\n",
        "     super().__init__()\n",
        "     self.labels = labels\n",
        "     self.blank = blank\n",
        "  def forward(self,emission:torch.Tensor) ->str:\n",
        "    # emission shape: (batch, frame, num_labels)\n",
        "    # We are interested in the first item in the batch\n",
        "    emission = emission[0] # shape: (frame, num_labels)\n",
        "    indices = torch.argmax(emission,dim =-1) # shape: (frame,)\n",
        "    indices = torch.unique_consecutive(indices,dim =-1) # shape: (unique_frames,)\n",
        "    indices = [i for i in indices if i != self.blank]\n",
        "    return \"\".join([self.labels[i] for i in indices])"
      ],
      "metadata": {
        "id": "II9UOQ0yJzHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = GreedyCTCDecoder(labels=bundle.get_labels())\n",
        "transcript = decoder(emission)"
      ],
      "metadata": {
        "id": "yKbWgpQPK9Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transcript)"
      ],
      "metadata": {
        "id": "QD4JuMnvLjcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
      ],
      "metadata": {
        "id": "Fj3syBTwsvD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio,rate = librosa.load(\"/content/0017_001731.wav\",sr = 16000)\n",
        "print(audio)\n",
        "print(rate)"
      ],
      "metadata": {
        "id": "gCcndhFztHgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KqO7kp6ctV18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_values = tokenizer(audio,return_tensors=\"pt\").input_values"
      ],
      "metadata": {
        "id": "CY5XfXfWtzJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(input_values).logits"
      ],
      "metadata": {
        "id": "iyMNhFdwt-vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = torch.argmax(logits,dim=-1)"
      ],
      "metadata": {
        "id": "FaiD2e5WuFS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = tokenizer.batch_decode(prediction)[0]\n",
        "print(transcription)"
      ],
      "metadata": {
        "id": "lJvRrQ1quMtB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}